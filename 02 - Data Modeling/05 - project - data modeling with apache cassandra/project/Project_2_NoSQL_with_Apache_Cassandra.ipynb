{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: NoSQL Data Modeling with Apache Cassandra\n",
    "<img src=\"images/cassandralogo.png\" width=\"250\" height=\"250\" align=\"middle\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview\n",
    "The fictional company, Sparkify, wants be able to analyze their song play data for their streaming music app platform. Currently the song play data resides in a directory CSV files, so an ETL pipeline is needed before the data can be loaded into a database. The pipeline will scrape the CSV files from the event directory and combined them into a denormalized, flat CSV file. After the data is combined, it can be loaded into Apache Cassandra tables designed for the example queries provided by the firm's analytics team."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table of Contents\n",
    "- [Part 1 - ETL Pipeline for Pre-Processing the Files](#ETL-pipeline)\n",
    "    + [Import Python Packages](#import-libraries)\n",
    "    + [Creating list of filepaths to process original event csv data files](#scrape-filepaths)\n",
    "    + [Processing the files to create the data file csv that will be used for Apache Casssandra tables](#combine-csv-files)\n",
    "    + [Contents of CSV file](#check-csv)\n",
    "- [Part II - Apache Cassandra queries](#cassandra-queries)\n",
    "    + [Setup Cassandra environment](#cassandra-setup)\n",
    "        - [Creating a Cluster](#creating-cluster)\n",
    "        - [Create Keyspace](#create-keyspace)\n",
    "        - [Set Keyspace](#set-keyspace)\n",
    "        - [Set Cassandra's `row factory` to created `pandas_factory`](#set-row_factory)\n",
    "    + [Queries](#queries)\n",
    "        - [Query 1](#query1)\n",
    "            + [CREATE TABLE for query](#query1-create)\n",
    "            + [INSERT data from csv file](#query1-insert)\n",
    "            + [SELECT statement for query](#query1-select)\n",
    "        - [Query 2](#query2)\n",
    "            + [CREATE TABLE for query](#query2-create)\n",
    "            + [INSERT data from csv file](#query2-insert)\n",
    "            + [SELECT statement for query](#query2-select)\n",
    "        - [Query 3](#query3)\n",
    "            + [CREATE TABLE for query](#query3-create)\n",
    "            + [INSERT data from csv file](#query3-insert)\n",
    "            + [SELECT statement for query](#query3-select)\n",
    "    + [Drop the tables before closing out the sessions](#drop-tables)\n",
    "    + [Close the session and cluster connection](#close-session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ETL-pipeline\"></a>\n",
    "# Part I. ETL Pipeline for Pre-Processing the Files\n",
    "The log files are currently located in the `/event_data` directory with naming in the form `YYYY-mm-dd-events.csv`. These files need to be combined into a single file for easier loading when it comes time to create tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"import-libraries\"></a>\n",
    "#### Import Python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Python packages \n",
    "import pandas as pd\n",
    "import cassandra\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"scrape-filepaths\"></a>\n",
    "#### Creating list of filepaths to process original event csv data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/workspace\n"
     ]
    }
   ],
   "source": [
    "# checking your current working directory\n",
    "print(os.getcwd())\n",
    "\n",
    "# Get your current folder and subfolder event data\n",
    "filepath = os.getcwd() + '/event_data'\n",
    "\n",
    "# Create a for loop to create a list of files and collect each filepath\n",
    "for root, dirs, files in os.walk(filepath):\n",
    "    \n",
    "# join the file path and roots with the subdirectories using glob\n",
    "    file_path_list = glob.glob(os.path.join(root,'*'))\n",
    "    #print(file_path_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"combine-csv-files\"></a>\n",
    "#### Processing the files to create the data file csv that will be used for Apache Casssandra tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiating an empty list of rows that will be generated from each file\n",
    "full_data_rows_list = [] \n",
    "    \n",
    "# for every filepath in the file path list \n",
    "for f in file_path_list:\n",
    "\n",
    "# reading csv file \n",
    "    with open(f, 'r', encoding = 'utf8', newline='') as csvfile: \n",
    "        # creating a csv reader object \n",
    "        csvreader = csv.reader(csvfile) \n",
    "        next(csvreader)\n",
    "        \n",
    "        # extracting each data row one by one and append it        \n",
    "        for line in csvreader:\n",
    "            #print(line)\n",
    "            full_data_rows_list.append(line) \n",
    "            \n",
    "# uncomment the code below if you would like to get total number of rows \n",
    "#print(len(full_data_rows_list))\n",
    "# uncomment the code below if you would like to check to see what the list of event data rows will look like\n",
    "#print(full_data_rows_list)\n",
    "\n",
    "# creating a smaller event data csv file called event_datafile_full csv that will be used to insert data into the \\\n",
    "# Apache Cassandra tables\n",
    "csv.register_dialect('myDialect', quoting=csv.QUOTE_ALL, skipinitialspace=True)\n",
    "\n",
    "with open('event_datafile_new.csv', 'w', encoding = 'utf8', newline='') as f:\n",
    "    writer = csv.writer(f, dialect='myDialect')\n",
    "    writer.writerow(['artist','firstName','gender','itemInSession','lastName','length',\\\n",
    "                'level','location','sessionId','song','userId'])\n",
    "    for row in full_data_rows_list:\n",
    "        if (row[0] == ''):\n",
    "            continue\n",
    "        writer.writerow((row[0], row[2], row[3], row[4], row[5], row[6], row[7], row[8], row[12], row[13], row[16]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6821\n"
     ]
    }
   ],
   "source": [
    "# check the number of rows in your csv file\n",
    "with open('event_datafile_new.csv', 'r', encoding = 'utf8') as f:\n",
    "    print(sum(1 for line in f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"check-csv\"></a>\n",
    "#### There should now be a CSV file titled `event_datafile_new.csv` located within the current working directory.\n",
    "The event_datafile_new.csv contains the following columns: \n",
    "- artist \n",
    "- firstName of user\n",
    "- gender of user\n",
    "- item number in session\n",
    "- last name of user\n",
    "- length of the song\n",
    "- level (paid or free song)\n",
    "- location of the user\n",
    "- sessionId\n",
    "- song title\n",
    "- userId\n",
    "\n",
    "The image below is a screenshot of what the denormalized data should appear like in the <font color=red>**event_datafile_new.csv**</font> after the code above is run:<br>\n",
    "\n",
    "<img src=\"images/image_event_datafile_new.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The contents of `event_datafile_new.csv` can be checked by loading the data into a pandas `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_datafile_df = pd.read_csv('event_datafile_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>firstName</th>\n",
       "      <th>gender</th>\n",
       "      <th>itemInSession</th>\n",
       "      <th>lastName</th>\n",
       "      <th>length</th>\n",
       "      <th>level</th>\n",
       "      <th>location</th>\n",
       "      <th>sessionId</th>\n",
       "      <th>song</th>\n",
       "      <th>userId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Muse</td>\n",
       "      <td>Harper</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>Barrett</td>\n",
       "      <td>209.50159</td>\n",
       "      <td>paid</td>\n",
       "      <td>New York-Newark-Jersey City, NY-NJ-PA</td>\n",
       "      <td>275</td>\n",
       "      <td>Supermassive Black Hole (Twilight Soundtrack V...</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beastie Boys</td>\n",
       "      <td>Harper</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>Barrett</td>\n",
       "      <td>161.56689</td>\n",
       "      <td>paid</td>\n",
       "      <td>New York-Newark-Jersey City, NY-NJ-PA</td>\n",
       "      <td>275</td>\n",
       "      <td>Lighten Up</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Shakira</td>\n",
       "      <td>Harper</td>\n",
       "      <td>M</td>\n",
       "      <td>3</td>\n",
       "      <td>Barrett</td>\n",
       "      <td>145.84118</td>\n",
       "      <td>paid</td>\n",
       "      <td>New York-Newark-Jersey City, NY-NJ-PA</td>\n",
       "      <td>275</td>\n",
       "      <td>Pienso En Ti</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         artist firstName gender  itemInSession lastName     length level  \\\n",
       "0          Muse    Harper      M              1  Barrett  209.50159  paid   \n",
       "1  Beastie Boys    Harper      M              2  Barrett  161.56689  paid   \n",
       "2       Shakira    Harper      M              3  Barrett  145.84118  paid   \n",
       "\n",
       "                                location  sessionId  \\\n",
       "0  New York-Newark-Jersey City, NY-NJ-PA        275   \n",
       "1  New York-Newark-Jersey City, NY-NJ-PA        275   \n",
       "2  New York-Newark-Jersey City, NY-NJ-PA        275   \n",
       "\n",
       "                                                song  userId  \n",
       "0  Supermassive Black Hole (Twilight Soundtrack V...      42  \n",
       "1                                         Lighten Up      42  \n",
       "2                                       Pienso En Ti      42  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_datafile_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"cassandra-queries\"></a>\n",
    "# Part II. Apache Cassandra queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apache Cassandra was chosen for the database because it has high availability and partition tolerance. The price for these benefits is that there are no multi-table `JOIN`s like in a relational database, requiring specialized tables for each query. Therefore, to setup the database, more information about what specific queries is required. Due to lack of normalization in the database, the denormalized, flat CSV file created in the first step is perfect for creating the tables in Cassandra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"cassandra-setup\"></a>\n",
    "### Setup Cassandra environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"creating-cluster\"></a>\n",
    "#### Creating a Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This should make a connection to a Cassandra instance your local machine \n",
    "# (127.0.0.1)\n",
    "\n",
    "from cassandra.cluster import Cluster\n",
    "cluster = Cluster()\n",
    "\n",
    "# To establish connection and begin executing queries, need a session\n",
    "session = cluster.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"create-keyspace\"></a>\n",
    "#### Create Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    session.execute(\"\"\"\n",
    "    CREATE KEYSPACE IF NOT EXISTS sparkify_events\n",
    "    WITH REPLICATION = \n",
    "    { 'class' : 'SimpleStrategy', 'replication_factor' : 1 }\"\"\"\n",
    ")\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"set-keyspace\"></a>\n",
    "#### Set Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    session.set_keyspace('sparkify_events')\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"set-row_factory\"></a>\n",
    "#### Set Cassandra's `row factory` to created `pandas_factory`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pandas_factory(columns, rows):\n",
    "    return pd.DataFrame(rows, columns=columns)\n",
    "session.row_factory = pandas_factory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Create queries to ask the provided three questions of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: Remember, with Apache Cassandra you model the database tables on the queries you want to run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate column numbers for csv `line[index]` statments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'artist'),\n",
       " (1, 'firstName'),\n",
       " (2, 'gender'),\n",
       " (3, 'itemInSession'),\n",
       " (4, 'lastName'),\n",
       " (5, 'length'),\n",
       " (6, 'level'),\n",
       " (7, 'location'),\n",
       " (8, 'sessionId'),\n",
       " (9, 'song'),\n",
       " (10, 'userId')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(enumerate(event_datafile_df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"query1\"></a>\n",
    "### Query 1: Give the artist, song title and song's length in the music app history that was heard during  sessionId = 338, and itemInSession  = 4\n",
    "This query is looking at what songs were played by session and when in the session, which looks like a song play history. Therefore, the table will have the name `song_play_history` and have a compound `PRIMARY KEY` of session ID and what item the song was during that session (item in session), since multiple songs are expected per session. The other information in the table is going to be what the Sparkify team is looking for -- artist, song title, and duration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"query1-create\"></a>\n",
    "#### `CREATE TABLE` for query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give the artist, song title and song's length in the music app history that was heard during \\\n",
    "# sessionId = 338, and itemInSession = 4\n",
    "\n",
    "query = \"CREATE TABLE IF NOT EXISTS song_play_history \"\n",
    "query = query + \"(session_id int, \\\n",
    "                  item_in_session int, \\\n",
    "                  artist text, \\\n",
    "                  song_title text, \\\n",
    "                  song_length decimal, \\\n",
    "                  PRIMARY KEY (session_id, item_in_session))\"\n",
    "\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"query1-insert\"></a>\n",
    "#### `INSERT` data from csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# We have provided part of the code to set up the CSV file. Please complete the Apache Cassandra code below\n",
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "        # Assign the INSERT statements into the `query` variable\n",
    "        query = \"INSERT INTO song_play_history (session_id, item_in_session, artist, song_title, song_length)\"\n",
    "        query = query + \" VALUES (%s, %s, %s, %s, %s)\"\n",
    "        # Assign which column element should be assigned for each column in the INSERT statement.\n",
    "        session.execute(query, (int(line[8]), int(line[3]), line[0], line[9], float(line[5])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"query1-select\"></a>\n",
    "#### `SELECT` statement for query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song_title</th>\n",
       "      <th>song_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Faithless</td>\n",
       "      <td>Music Matters (Mark Knight Dub)</td>\n",
       "      <td>495.3073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      artist                       song_title song_length\n",
       "0  Faithless  Music Matters (Mark Knight Dub)    495.3073"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SELECT statement to verify the data was entered into the table\n",
    "query = \"SELECT artist, song_title, song_length \\\n",
    "         FROM song_play_history \\\n",
    "         WHERE session_id = 338 \\\n",
    "         AND item_in_session = 4\"\n",
    "try:\n",
    "    # get rows from query\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "rows._current_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"query2\"></a>\n",
    "### Query 2: Give only the following: name of artist, song (sorted by itemInSession) and user (first and last name) for userid = 10, sessionid = 182\n",
    "This query is looking at song information of a user during a specific session, or user session song history. The session ID would be expected to be unique, but since `WHERE` requires the search term to be a partition key, the user ID needs to be part of the `PRIMARY KEY`. Therefore, the `user_session_song_history` table will need a compound `PRIMARY KEY` of `user_id` and `session_id`. Since the song plays need to be sorted by occurence within the session, the cluster column of `item_in_session` will be added."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"query2-create\"></a>\n",
    "#### `CREATE TABLE` for query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query 2: Give only the following: name of artist, song (sorted by itemInSession) and user (first and last name)\n",
    "# for userid = 10, sessionid = 182\n",
    "\n",
    "query = \"CREATE TABLE IF NOT EXISTS user_session_song_history\"\n",
    "query = query + \"(user_id int, \\\n",
    "                  session_id int, \\\n",
    "                  item_in_session int, \\\n",
    "                  artist text, \\\n",
    "                  song_title text, \\\n",
    "                  first_name text, \\\n",
    "                  last_name text, \\\n",
    "                  PRIMARY KEY ((user_id, session_id), item_in_session))\"\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"query2-insert\"></a>\n",
    "#### `INSERT` data from csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have provided part of the code to set up the CSV file. Please complete the Apache Cassandra code below#\n",
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "        # Assign the INSERT statements into the `query` variable\n",
    "        query = \"INSERT INTO user_session_song_history (user_id, session_id, item_in_session, artist, song_title, first_name, last_name)\"\n",
    "        query = query + \" VALUES (%s, %s, %s, %s, %s, %s, %s)\"\n",
    "        # Assign which column element should be assigned for each column in the INSERT statement.\n",
    "        session.execute(query, (int(line[10]), int(line[8]), int(line[3]), line[0], line[9], line[1], line[4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"query2-select\"></a>\n",
    "#### `SELECT` statement for query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song_title</th>\n",
       "      <th>item_in_session</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Down To The Bone</td>\n",
       "      <td>Keep On Keepin' On</td>\n",
       "      <td>0</td>\n",
       "      <td>Sylvie</td>\n",
       "      <td>Cruz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Three Drives</td>\n",
       "      <td>Greece 2000</td>\n",
       "      <td>1</td>\n",
       "      <td>Sylvie</td>\n",
       "      <td>Cruz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sebastien Tellier</td>\n",
       "      <td>Kilometer</td>\n",
       "      <td>2</td>\n",
       "      <td>Sylvie</td>\n",
       "      <td>Cruz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lonnie Gordon</td>\n",
       "      <td>Catch You Baby (Steve Pitron &amp; Max Sanna Radio...</td>\n",
       "      <td>3</td>\n",
       "      <td>Sylvie</td>\n",
       "      <td>Cruz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              artist                                         song_title  \\\n",
       "0   Down To The Bone                                 Keep On Keepin' On   \n",
       "1       Three Drives                                        Greece 2000   \n",
       "2  Sebastien Tellier                                          Kilometer   \n",
       "3      Lonnie Gordon  Catch You Baby (Steve Pitron & Max Sanna Radio...   \n",
       "\n",
       "   item_in_session first_name last_name  \n",
       "0                0     Sylvie      Cruz  \n",
       "1                1     Sylvie      Cruz  \n",
       "2                2     Sylvie      Cruz  \n",
       "3                3     Sylvie      Cruz  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SELECT statement to verify the data was entered into the table\n",
    "query = \"SELECT artist, song_title, item_in_session, first_name, last_name \\\n",
    "         FROM user_session_song_history \\\n",
    "         WHERE user_id = 10 \\\n",
    "         AND session_id = 182\"\n",
    "try:\n",
    "    # get rows from query\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "rows._current_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"query3\"></a>\n",
    "### Query 3: Give every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n",
    "This query checks which users played a specific song, so a good name would be `who_played_a_song`. In order to have a unique `PRIMARY KEY`, the unique `user_id` can be added to the `song_title` to create a unique compound key. Using the `user_id` instead of the first and last name columns will ensure all users, including those with the same name, are reported. The query doesn't require the names to be ordered, so no need to worry about clustering columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"query3-create\"></a>\n",
    "#### `CREATE TABLE` for query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query 3: Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n",
    "\n",
    "query = \"CREATE TABLE IF NOT EXISTS who_played_a_song\"\n",
    "query = query + \"(song_title text, \\\n",
    "                  user_id int, \\\n",
    "                  last_name text, \\\n",
    "                  first_name text, \\\n",
    "                  PRIMARY KEY (song_title, user_id))\"\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)                         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"query3-insert\"></a>\n",
    "#### `INSERT` data from csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have provided part of the code to set up the CSV file. Please complete the Apache Cassandra code below#\n",
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "        # Assign the INSERT statements into the `query` variable\n",
    "        query = \"INSERT INTO who_played_a_song (song_title, user_id, last_name, first_name)\"\n",
    "        query = query + \" VALUES (%s, %s, %s, %s)\"\n",
    "        # Assign which column element should be assigned for each column in the INSERT statement.\n",
    "        session.execute(query, (line[9], int(line[10]), line[4], line[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"query3-select\"></a>\n",
    "#### `SELECT` statement for query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29</td>\n",
       "      <td>Jacqueline</td>\n",
       "      <td>Lynch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80</td>\n",
       "      <td>Tegan</td>\n",
       "      <td>Levine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>95</td>\n",
       "      <td>Sara</td>\n",
       "      <td>Johnson</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  first_name last_name\n",
       "0       29  Jacqueline     Lynch\n",
       "1       80       Tegan    Levine\n",
       "2       95        Sara   Johnson"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SELECT statement to verify the data was entered into the table\n",
    "query = \"SELECT user_id, first_name, last_name \\\n",
    "         FROM who_played_a_song \\\n",
    "         WHERE song_title='All Hands Against His Own'\"\n",
    "try:\n",
    "    # get rows from query\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "rows._current_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"drop-tables\"></a>\n",
    "### Drop the tables before closing out the sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables_to_drop = ['song_play_history',\n",
    "                  'user_session_song_history',\n",
    "                  'who_played_a_song']\n",
    "for table_name in tables_to_drop:\n",
    "    query = \"DROP TABLE IF EXISTS %s\"\n",
    "    try:\n",
    "        session.execute(query % table_name)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"close-session\"></a>\n",
    "### Close the session and cluster connection¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.shutdown()\n",
    "cluster.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
